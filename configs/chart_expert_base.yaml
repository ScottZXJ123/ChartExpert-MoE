# ChartExpert-MoE Base Configuration
# This file contains the basic configuration for the ChartExpert-MoE model

model_name: "chart_expert_moe_base"
version: "0.1.0"

# Global model parameters
hidden_size: 768
vocab_size: 32000
max_length: 512
aux_loss_weight: 0.01

# Vision encoder configuration
vision_encoder:
  encoder_type: "clip"  # Options: clip, siglip, dinov2, moonvit
  model_name: "openai/clip-vit-base-patch32"
  hidden_size: 768
  max_patches: 196
  use_fp16: false

# LLM backbone configuration  
llm_backbone:
  model_name: "meta-llama/Llama-2-7b-hf"  # Options: llama, qwen, gemma
  hidden_size: 4096
  vision_hidden_size: 768
  use_fp16: true
  use_device_map: true

# MoE layer configuration
moe:
  num_experts: 12
  top_k: 2
  capacity_factor: 1.25
  aux_loss_weight: 0.01
  load_balancing: true
  noisy_gating: true
  noise_eps: 0.01

# Expert module configurations
experts:
  # Visual-Spatial & Structural Experts
  layout:
    expert_type: "layout"
    hidden_size: 768
    expert_hidden_size: 1024
    dropout_rate: 0.1
    visual_feature_dim: 2048
    use_object_detection: true
    num_heads: 8
  
  ocr:
    expert_type: "ocr"
    hidden_size: 768
    expert_hidden_size: 1024
    dropout_rate: 0.1
    num_heads: 8
  
  scale:
    expert_type: "scale" 
    hidden_size: 768
    expert_hidden_size: 1024
    dropout_rate: 0.1
  
  geometric:
    expert_type: "geometric"
    hidden_size: 768
    expert_hidden_size: 1024
    dropout_rate: 0.1
  
  trend:
    expert_type: "trend"
    hidden_size: 768
    expert_hidden_size: 1024
    dropout_rate: 0.1
  
  # Semantic & Relational Experts
  query:
    expert_type: "query"
    hidden_size: 768
    expert_hidden_size: 1024
    dropout_rate: 0.1
    num_heads: 8
  
  numerical:
    expert_type: "numerical"
    hidden_size: 768
    expert_hidden_size: 1024
    dropout_rate: 0.1
  
  integration:
    expert_type: "integration"
    hidden_size: 768
    expert_hidden_size: 1024
    dropout_rate: 0.1
    num_heads: 8
  
  # Cross-Modal Fusion & Reasoning Experts  
  alignment:
    expert_type: "alignment"
    hidden_size: 768
    expert_hidden_size: 1024
    dropout_rate: 0.1
    num_heads: 8
  
  chart_to_graph:
    expert_type: "chart_to_graph"
    hidden_size: 768
    expert_hidden_size: 1024
    dropout_rate: 0.1
    num_gnn_layers: 3
    graph_hidden_dim: 512
    num_heads: 8
  
  # Cognitive Effort Modulation Experts
  shallow_reasoning:
    expert_type: "shallow_reasoning"
    hidden_size: 768
    expert_hidden_size: 512
    dropout_rate: 0.1
    num_heads: 4
    fast_mode: true
  
  orchestrator:
    expert_type: "orchestrator"
    hidden_size: 768
    expert_hidden_size: 2048
    dropout_rate: 0.1
    num_heads: 12

# Routing configuration
routing:
  routing_strategy: "learned"
  hidden_size: 768
  num_experts: 12
  top_k: 2
  load_balancing: true
  balance_weight: 0.01
  capacity_factor: 1.25
  batch_priority_routing: true

# Fusion configuration
fusion:
  fusion_type: "dynamic_gated"  # Options: concat, attention, dynamic_gated, film_guided, graph_based
  hidden_size: 768
  vision_hidden_size: 768
  text_hidden_size: 4096
  num_heads: 8
  dropout_rate: 0.1
  
  # FILM-guided fusion options
  film_guided:
    enabled: false
    language_conditioning: true
    visual_modulation: true
  
  # Graph-based fusion options
  graph_based:
    enabled: false
    num_gnn_layers: 3
    graph_hidden_dim: 512
    use_gat: true

# Training configuration
training:
  # Multi-stage training
  stages:
    foundation:
      epochs: 5
      learning_rate: 1e-4
      batch_size: 32
      warmup_steps: 1000
      
    joint_pretrain:
      epochs: 10
      learning_rate: 5e-5
      batch_size: 16
      warmup_steps: 2000
      
    chart_tuning:
      epochs: 15
      learning_rate: 2e-5
      batch_size: 8
      warmup_steps: 1000
      
    expert_specialization:
      epochs: 10
      learning_rate: 1e-5
      batch_size: 8
      warmup_steps: 500
      
    chartmuseum_finetune:
      epochs: 5
      learning_rate: 5e-6
      batch_size: 4
      warmup_steps: 200

  # Optimization
  optimizer: "adamw"
  weight_decay: 0.01
  gradient_clip_norm: 1.0
  
  # Scheduler
  scheduler: "cosine"
  min_learning_rate: 1e-7
  
  # Mixed precision
  use_fp16: true
  use_deepspeed: false

# Data configuration
data:
  max_length: 512
  image_size: [224, 224]
  use_native_resolution: true  # For MoonViT
  
  # Dataset paths
  chartmuseum_cache_dir: "./data/cache/chartmuseum"
  chartqa_cache_dir: "./data/cache/chartqa"
  plotqa_data_dir: "./data/plotqa"
  
  # Data augmentation
  augmentation:
    enabled: true
    # Visual augmentations (preserve chart semantics)
    rotation_range: 5
    brightness_range: 0.1
    contrast_range: 0.1
    color_jitter: 0.05
    # Chart-specific augmentations
    axis_noise: 0.02  # Add noise to axis labels
    legend_position_variation: true
    synthetic_chart_generation: true
    
  # Robustness enhancements
  robustness:
    add_visual_perturbations: true
    perturbation_types: ["color_shift", "style_transfer", "compression"]
    perturbation_probability: 0.2

# Evaluation configuration
evaluation:
  metrics:
    - "accuracy"
    - "rouge"
    - "bleu"
    - "bert_score"
    - "visual_reasoning_gap"  # Custom metric
    - "error_analysis"  # Detailed error categorization
  
  # ChartMuseum specific evaluation
  chartmuseum:
    reasoning_types:
      - "text_dominant"
      - "visual_dominant"  
      - "text_visual_combined"
      - "comprehensive"
    
    chart_types:
      - "bar_chart"
      - "line_chart"
      - "pie_chart"
      - "scatter_plot"
      - "area_chart"
      - "heatmap"
      - "box_plot"
      - "radar_chart"
    
    error_categories:
      - "symbol_selection"
      - "visual_comparison"
      - "trajectory_tracking"
      - "xy_value_identification"
      - "ocr_error"
      - "logical_error"
      - "hallucination"
      
  # Human evaluation
  human_eval:
    enabled: false
    sample_size: 100
    criteria: ["correctness", "coherence", "faithfulness"]

# Logging and monitoring
logging:
  log_level: "INFO"
  log_dir: "./logs"
  tensorboard_dir: "./logs/tensorboard"
  wandb:
    enabled: true
    project: "chartexpert-moe"
    entity: "your-entity"
  
  # Checkpoint configuration
  checkpoints:
    save_dir: "./checkpoints"
    save_every_n_steps: 1000
    keep_last_n: 5
    save_best: true

# Hardware configuration
hardware:
  device: "auto"  # auto, cpu, cuda
  num_gpus: 1
  mixed_precision: true
  gradient_checkpointing: false
  
  # DeepSpeed configuration (if enabled)
  deepspeed:
    stage: 2
    offload_optimizer: false
    offload_params: false

# Performance optimization
optimization:
  # FlashAttention
  use_flash_attention: true
  attention_dropout: 0.1
  
  # Quantization
  quantization:
    enabled: false  # Enable for deployment
    type: "dynamic"  # Options: dynamic, static, qat
    bits: 8
    quantize_experts: true
    
  # Pruning
  pruning:
    enabled: false  # Enable after training
    ratio: 0.1
    method: "structured"
    prune_experts: true
    expert_importance_threshold: 0.05
    
  # Knowledge distillation
  distillation:
    enabled: false
    teacher_model: "chart_expert_large"
    temperature: 3.0
    alpha: 0.7
    
  # Inference optimization
  inference:
    batch_priority_routing: true
    expert_caching: true
    dynamic_batching: true
    max_batch_size: 32
    
  # Memory optimization
  memory:
    gradient_checkpointing: true
    expert_offloading: false  # For very large models
    mixed_precision_training: true 